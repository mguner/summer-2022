{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08-Statistics.ipynb","provenance":[],"authorship_tag":"ABX9TyMjsI27sQL9SgBTnH8uCCu+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZwqAel94Rg85"},"source":["<table align=\"center\">\n","   <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ds5110/summer-2021/blob/master/08-Statistics.ipynb\">\n","<img src=\"https://github.com/ds5110/summer-2021/raw/master/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"8AiailffJXNn"},"source":["# 08-Statistics\n","\n","* Statistical inference\n","* Distributions of statistics\n","* Confidence intervals\n","* Hypothesis tests\n","\n","## Reading\n","\n","* Chapter 3 of [Introduction to Statistical Learning, 1st edition](https://www.statlearning.com/) by James, Witten, Hastie and Tibshirani -- statlearning.com\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JzTRDSLUtRL3"},"source":["# Definitions\n","\n","### Population vs sample\n","\n","* Assume data is a random sample taken from a population\n","* Want to know truth about the population \n","* Use sample to make inferences about the whole population\n","\n","### Parameter versus statistic\n","\n","* Population parameter\n","  * True value in the population of interest\n","  * E.g., true population average (mean)\n","* Sample statistic\n","  * Summary measure calculated from the sample data\n","  * E.g.,sample mean\n","* Statistics estimate parameters\n","\n","### Assumptions\n","\n","* Sample data are representative of the population\n","* We can use the data to estimate the probability distribution of the sample statistic(s)\n","\n","### Quantifying uncertainty\n","\n","* How accurately does a sample statistic estimate a population parameter?\n","* Identify the distribution of the statistic\n","* Use this probability distribution to quantify uncertainty"]},{"cell_type":"markdown","metadata":{"id":"Mn9ZnuAFSd4a"},"source":["# Advertising dataset (revisited)\n","\n","**Key Questions:**\n","\n","* Q: How \"strong\" is the evidence that advertising impacts sales? \n","  * If it's not strong, then maybe it's not worth spending any money.\n","* Q: Should you choose \"TV\", \"radio\" or \"newspaper\"...\n","  *  ...or perhaps some combination?\n","* Q: Suppose you decide on a model, can you quantify the accuracy of the prediction?"]},{"cell_type":"code","metadata":{"id":"8kGttze9HZXe"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9VaOjNf4Ii1c"},"source":["# Load the advertising dataset\n","\n","url = \"https://www.statlearning.com/s/Advertising.csv\"\n"," \n","df = pd.read_csv(url, index_col=0)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uauQ8VWYZO22"},"source":["# Plot least-squares line with Seaborn -- a convenient visualization tool.\n","red_kws = {'color':'red'}\n","sns.regplot(x=\"TV\", y=\"sales\", data=df, line_kws=red_kws, order=1);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ppi4lqwXZ3lG"},"source":["## Linear regression with scikit-learn\n","\n","We've used linear regression with Seaborn and Scikit-learn.\n","\n","$$\n","y = \\beta_0 + \\beta_1 X + \\epsilon\n","$$\n","\n","* [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html) with the diabetes dataset -- scikit-learn.org\n","\n","But we haven't had statistical tools to provide quantitative answers to the questions above."]},{"cell_type":"code","metadata":{"id":"dZu26KquZyuk"},"source":["from sklearn import linear_model\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import train_test_split\n","\n","def univariate_model(df, name):\n","  X = df[name].values[:, None] # Note the shape change\n","  y = df['sales']\n","\n","  regr = linear_model.LinearRegression()\n","  regr.fit(X, y)\n","  y_pred = regr.predict(X)\n","\n","  plt.plot(X, y_pred, color=\"crimson\", label=name + \" model\");\n","  \n","  plt.scatter(X, y, color='black', s=10, label='data')\n","  plt.xlabel(name + ' budget')\n","  plt.ylabel('sales')\n","  plt.plot([X.min(), X.max()], [0,0], 'k:')\n","  plt.legend();\n","\n","plt.figure(figsize=(20,4))\n","ax = plt.subplot(1,3,1)\n","for i, name in enumerate(['TV', 'radio', 'newspaper']):\n","  plt.subplot(1,3,i + 1, sharex=ax, sharey=ax)\n","  univariate_model(df, name)\n","\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1O36XGH30Q8"},"source":["# Standard error of the mean\n","\n","Your dataset: $N$ measurements $y_i$ of some process $\\mu$.\n","\n","\n","Your model:\n","\n","$$\n","y_i = \\mu + \\epsilon_i\n","$$\n","\n","\n","* $\\mu$ represents the \"predictable\" part of $y_i$,\n","* $\\mu$ is a constant,\n","* $\\epsilon_i$ represents random measurement error (noise).\n","\n","You don't know $\\mu$, so you'll estimate it from the data. Likewise, you'll use the data to quantify the accuracy of the estimate. That requires additional modeling assumptions. For example, you could assume the mean of $\\epsilon_i$ is zero. Then $\\mu$ should be the mean of $y_i$, but that depends on what you mean by mean:\n","\n","* arithmetic mean (average)\n","* population mean (expected value)\n","* geometric mean (Nth root of a product of N values)\n","* weighted arithmetic mean\n","* etc.\n","\n","We'll assume that:\n","\n","* $\\mu$ is the [expected value](https://en.wikipedia.org/wiki/Expected_value) (i.e., mean means population mean, which is defined in terms of probability distributions)\n","* $\\epsilon$ has zero mean,\n","* $\\epsilon$ has constant variance $\\mathrm{Var}(\\epsilon) = \\sigma^2$  ([homoscedastic](https://en.wikipedia.org/wiki/Homoscedasticity))\n","* $\\epsilon_i$ is statistically \"well behaved\" ([independent and identically distributed](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) or IID)\n","\n","With these assumptions, it's sensible to estimate $\\mu$ using the arithmetic mean of the data (sample average):\n","\n","$$\n","\\bar{y} = \\frac{1}{N} \\sum_{i=1}^N y_i\n","$$\n","\n","along with a well known result from statistics to quantify the accuracy of our estimate:\n","\n","$$\n","\\mathrm{SE}(\\bar{\\mu})^2 = \\mathrm{Var}(\\bar{y}) = \\frac{\\sigma^2}{N}\n","$$\n","\n","The square root of $\\mathrm{Var}(\\bar{y})$\n","is also known as the \"standard error\" of the estimate $\\bar{\\mu}$ of $\\mu$. \n","\n","* The standard error tells us how much on average the estimate $\\hat{\\mu}$ departs from the actual value of $\\mu$.\n","* As you might expect intitutively, \n","$\\mathrm{SE}$ \n","decreases as $N$ increases. \n","* More specifically, $\\mathrm{SE}$  is inversely proportional to the square root of N.\n","\n","## Confidence intervals\n","\n","* Standard errors can be used to compute confidence intervals. \n","* A 95% confidence interval for $\\hat{\\mu}$ is defined as the range of values that will contain the true unknown value of $\\mu$ with 95% probability.\n","\n","## One more assumption\n","\n","Since we don't know $\\sigma^2$, we'll estimate it with the sample variance $s^2$:\n","\n","$$\n","\\sigma^2 \\approx\n","s^2 \\equiv \\frac{1}{N-1} \\sum_{i=1}^N (y_i - \\bar{y})^2\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"uwNDzuMLvz3I"},"source":["# Check the modeling assumptions\n","\n","* Do the errors have constant variance?\n","* If not, what can you do?\n","  * Nonlinear transformation of the data\n","  * Remove obvious outliers\n","  * Weighted least squares"]},{"cell_type":"code","metadata":{"id":"JDGRsSgx36sA"},"source":["def univariate_residuals(df, name):\n","  X = df[name].values[:, None] # Note the shape change\n","  y = df['sales']\n","\n","  regr = linear_model.LinearRegression()\n","  regr.fit(X, y)\n","  y_pred = regr.predict(X)\n","  resid = y - y_pred\n","  \n","  plt.scatter(X, resid, color='steelblue', s=10, label='residuals')\n","  plt.xlabel(name + ' budget')\n","  plt.ylabel('sales')\n","  plt.plot([X.min(), X.max()], [0,0], 'k:')\n","  plt.legend();\n","\n","plt.figure(figsize=(20,4))\n","ax = plt.subplot(1,3,1)\n","for i, name in enumerate(['TV', 'radio', 'newspaper']):\n","  plt.subplot(1,3,i + 1, sharex=ax, sharey=ax)\n","  univariate_residuals(df, name)\n","\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mis331y1WpEu"},"source":["# Assessing the impact of modeling assumptions\n","\n","We can assess the impact of modeling assumptions by simulating random behavior in the data.\n","\n","These types of simulations have the advantage that we know some of the true statistics. For example, the variance of uniform distribution:\n","\n","$$\n","\\int_{-\\frac{1}{2}}^{\\frac{1}{2}} x^2 dx = \n","\\frac{1}{3} x^3\\Biggr|_{-\\frac{1}{2}}^{\\frac{1}{2}}\n","= \\frac{1}{12}\n","$$\n","\n","We'll use these types of results to normalize variables in our assessments. \n","\n","The next cell defines a convenience function for visualizing histograms and comparing them to standard normal distributions."]},{"cell_type":"code","metadata":{"id":"UvL-PahY8Wmr"},"source":["from scipy.stats import norm\n","import random\n","\n","# Convenience function for plotting normalized histogram, KDE and Gaussian\n","def my_hist(x, y):\n","  plt.figure(figsize=(15,4))\n","  ax = plt.subplot(1,2,1)\n","  sns.scatterplot(x=x, y=y, ax=ax);\n","  plt.plot([0, len(x)], [0,0], \"k:\")\n","\n","  # Plot the normalized histogram and KDE\n","  ax = plt.subplot(1,2,2)\n","  sns.histplot(y, ax=ax, stat=\"density\", kde=True, label=\"histogram\")\n","  sns.kdeplot(y, ax=ax)\n","\n","  # Add a label for the KDE -- the label will be used in the legend\n","  ax.get_lines()[0].set_label(\"KDE\")\n","\n","  # Plot the normal (Gaussian) distribution\n","  xg = np.linspace(-4,4)\n","  yg = norm.pdf(xg) # Compute the standard normal PDF\n","  ax.plot(xg, yg, c=\"crimson\", label='Gaussian')\n","\n","  # Label the plot\n","  ax.set_xlabel(\"Standard Deviations\")\n","  ax.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zxw9xe8SEKfe"},"source":["\n","# Distribution of the data\n","\n","The next cell simulates random noise from either a standard normal or uniform distribution.\n"]},{"cell_type":"code","metadata":{"id":"vS9xOTDVDXDk"},"source":["# For reproducibility\n","#random.seed(42)\n","\n","def gaussian(n):\n","  return np.array([random.gauss(0, 1) for i in range(n)])\n","\n","def uniform(n):\n","  a = np.sqrt(12)\n","  return np.array([a * random.uniform(-.5, .5) for i in range(n)])\n","\n","# Generate some random noise\n","n = 10\n","y = gaussian(n)\n","y = uniform(n)\n","\n","# Create the independent variable (linear sequence)\n","x = np.array(range(n))\n","\n","# Sample statistics\n","mu_hat = y.mean()\n","var_hat = ((y - mu_hat)**2).mean()\n","var_mu_hat = var_hat / n\n","se_mu_hat = np.sqrt(var_mu_hat)\n","print('sample average: {:.4f}'.format(mu_hat), \" (estimate of the mean)\")\n","print('sample variance: {:.4f}'.format(var_hat), \"(estimate of sigma-squared)\")\n","print('Var(sample average) {:.4f}'.format(var_mu_hat), \" (estimated with sample variance)\")\n","print('Standard Error of the mean: {:.3f}'.format(se_mu_hat), \" (ditto)\")\n","\n","# Custom scatterplot & histogram combo\n","my_hist(x, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MLawxzRoMb09"},"source":["# Distribution of the sample average\n","\n","The sample average of a standard normal random variable divided by $\\sigma / N$ itself has a standard normal distribution:\n","$$\n","\\frac{\\bar{y}}{\\sigma / \\sqrt{N}}\n","$$\n","\n","And the variable obtained by substituting $S$ for $\\sigma$, \n","$$\n","t = \\frac{\\bar{y}}{S / \\sqrt{N}}\n","$$\n","has a Student's t-distribution with N-1 degrees of freedom.\n","\n","The convenience function in the next cell makes it easy to investigate the impact of\n","* sample size, $N$...\n","* the Gaussian assumption...\n","\n","... when computing the sample average.\n","\n","What are the implications for $N = 3, 10, 30, 100, 1000$...?"]},{"cell_type":"code","metadata":{"id":"kX3Jvci0A8EM"},"source":["# Convenience function for simulating sample-average of a dataset\n","def sample_average(n):\n","  # random.seed(42)\n","\n","  # generate \"n\" random numbers with a standard normal distribution\n","  eps = [random.gauss(0, 1) for i in range(n)]\n","\n","  # generate \"n\" random variables from a uniform distribution with zero mean, unit variance\n","  #eps = [np.sqrt(12) * random.uniform(-.5, .5) for i in range(n)]\n","\n","  data = np.array(eps)\n","\n","  mu_hat = data.mean() # sample mean\n","  std = data.std() * np.sqrt(n / (n-1)) # sample standard deviation\n","\n","  return mu_hat, std\n","\n","# n is the number of measurements used to compute the sample average\n","n = 3\n","\n","# \"m\" is the number of experiments (ensemble members) used to compute\n","# the distribution of the sample mean based on \"n\" measurements\n","m = 1000\n","\n","# Accumulate\n","y = []\n","for i in range(m):\n","  mu_hat, std = sample_average(n)\n","  yp = mu_hat / (1 / np.sqrt(n))\n","  t = mu_hat / (std / np.sqrt(n))\n","\n","  y.append(t)\n","\n","x = np.array(list(range(m)))\n","y = np.array(y)\n","\n","my_hist(x,y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIZOPidUHihE"},"source":["# Central Limit Theorem\n","\n","* in many situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution\n","* this true even if the original variables themselves are not normally distributed\n","* the theorem is important because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions\n","\n","Ref: [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) -- wikipedia"]},{"cell_type":"markdown","metadata":{"id":"Nky5GPL6Rcsf"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"LGh38YV1nruu"},"source":["# Hypothesis testing\n","\n","You can test the null hypothesis that the mean is zero.\n","\n","$$\n","\\mathrm{H_0}: \\mu = 0\n","$$\n","\n","We'll reject the null hypothesis if the sample value is sufficiently large. We can use the standard error to quantify \"sufficiently large\". Use a t-statistic\n","\n","$$\n","t = \\frac{\\hat{\\mu}}{\\mathrm{SE}(\\hat{\\mu})}\n","$$\n","\n","with N-2 degrees of freedom to define a \"p-value\", which is the probability of observing any number equal to |t| or larger. We reject the null hypothesis if Typical p-value cutoffs for rejecting the null hypothesis are 5 or 1 %, which corresonds to a t-statistic of 2 or 2.75 if $n >> 10$.\n","\n","### Comparison with Gaussian\n","\n","* [t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) -- wikipedia\n","* [t-statistic](https://en.wikipedia.org/wiki/T-statistic) -- wikipedia\n","* [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test) -- wikipedia\n","\n"]},{"cell_type":"code","metadata":{"id":"lXA30PkRaVc1"},"source":["import statsmodels.api as sm\n","\n","X = df[['TV']].copy()\n","#X = sm.add_constant(X)\n","y = df['sales'].copy()\n","\n","# Fit regression model\n","results = sm.OLS(y, X).fit()\n","\n","# Inspect the results\n","print(results.summary())"],"execution_count":null,"outputs":[]}]}