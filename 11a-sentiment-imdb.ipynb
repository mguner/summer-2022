{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11a-sentiment-imdb.ipynb","provenance":[{"file_id":"1nOkjtnKPZTNpaol0d83PDVyq4l1h6Vl4","timestamp":1627983411371},{"file_id":"1DJzpqGgQWgpSDDeyv2LCRG1uxdUDOsOw","timestamp":1615305372570}],"collapsed_sections":[],"authorship_tag":"ABX9TyMHA6CeuDR27uzh4ET8RzYx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X2B0SXxHuBI9"},"source":["<table align=\"center\">\n","   <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ds5110/summer-2021/blob/master/11a-sentiment-imdb.ipynb\">\n","<img src=\"https://github.com/ds5110/summer-2021/raw/master/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n","</table>\n","\n","# 11a Sentiment analysis of IMDb dataset\n","\n","* Use logistic regression to classify labeled [IMDb movie reviews](http://ai.stanford.edu/~amaas/data/sentiment/)\n","* Python's [urllib.request](https://docs.python.org/3/library/urllib.request.html) for processing files \n","* Text processing with Python regular expressions\n","\n","### References\n","\n","* [IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/) -- stanford.edu\n","* Python Machine Learning, 3rd Edition (2019) Raschka & Mirjalili\n","  * Raschka's [ch08.ipynb](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch08/ch08.ipynb) -- github\n"]},{"cell_type":"markdown","metadata":{"id":"HeY2DfEPeE3n"},"source":["# Get the dataset\n","\n","* The next cell uses [urlib.request.urlretrieve](https://docs.python.org/3/library/urllib.request.html#urllib.request.URLopener.retrieve) to get a \"gzipped tar file\"\n","* The file is a compressed archive -- it cannot be read directly by Pandas\n","* Once you download the file locally, you can inspect the contents of the directories"]},{"cell_type":"code","metadata":{"id":"TYg3Bi1Ja860"},"source":["# Get the data file from the original source (takes ~30 seconds in Colab)\n","import os\n","import sys\n","import tarfile\n","import time\n","import urllib.request\n","\n","source = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n","target = 'aclImdb_v1.tar.gz'\n","\n","def reporthook(count, block_size, total_size):\n","    global start_time\n","    if count == 0:\n","        start_time = time.time()\n","        return\n","    duration = time.time() - start_time\n","    progress_size = int(count * block_size)\n","    speed = progress_size / (1024.**2 * duration)\n","    percent = count * block_size * 100. / total_size\n","\n","    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n","                    (percent, progress_size / (1024.**2), speed, duration))\n","    sys.stdout.flush()\n","\n","\n","if not os.path.isdir('aclImdb') and not os.path.isfile('aclImdb_v1.tar.gz'):\n","    urllib.request.urlretrieve(source, target, reporthook)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8SgSpDifR-X"},"source":["if not os.path.isdir('aclImdb'):\n","\n","    with tarfile.open(target, 'r:gz') as tar:\n","        tar.extractall()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIFh36Nege9P"},"source":["# Install Raschka's pyprind in Colab\n","# It's a progress bar -- no functional contribution.\n","!pip install pyprind"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRe_4fdigDpm"},"source":["# This cell takes about 1.5 minutes on Colab\n","import pyprind\n","import pandas as pd\n","import os\n","\n","# change the `basepath` to the directory of the\n","# unzipped movie dataset\n","\n","basepath = 'aclImdb'\n","\n","labels = {'pos': 1, 'neg': 0}\n","pbar = pyprind.ProgBar(50000)\n","df = pd.DataFrame()\n","for s in ('test', 'train'):\n","    for l in ('pos', 'neg'):\n","        path = os.path.join(basepath, s, l)\n","        for file in sorted(os.listdir(path)):\n","            with open(os.path.join(path, file), \n","                      'r', encoding='utf-8') as infile:\n","                txt = infile.read()\n","            df = df.append([[txt, labels[l]]], \n","                           ignore_index=True)\n","            pbar.update()\n","df.columns = ['review', 'sentiment']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KIA6WLpbpjiG"},"source":["# Shuffle the dataframe (reproducibly)\n","import numpy as np\n","\n","np.random.seed(0)\n","df = df.reindex(np.random.permutation(df.index))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Py0sjqVpVuQ"},"source":["assert df.shape == (50000, 2)\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yu3V0zuPwq6N"},"source":["# Read movie reviews from CSV in Raschka's github repo\n","# This cell replaces cells 2, 3 & 4\n","import os\n","import sys\n","import time\n","import pandas as pd\n","import urllib.request\n","\n","def reporthook(count, block_size, total_size):\n","    global start_time\n","    if count == 0:\n","        start_time = time.time()\n","        return\n","    duration = time.time() - start_time\n","    progress_size = int(count * block_size)\n","    speed = progress_size / (1024.**2 * duration)\n","    percent = count * block_size * 100. / total_size\n","\n","    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n","                    (percent, progress_size / (1024.**2), speed, duration))\n","    sys.stdout.flush()\n","\n","target = \"movie_data.csv.gz\"\n","source = \"https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/\" + target\n","if not os.path.isfile(target):\n","    urllib.request.urlretrieve(source, target, reporthook)\n","\n","df = pd.read_csv(target, compression='gzip')\n","\n","assert df.shape == (50000, 2)\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oe1DydLpYDhj"},"source":["# Cleaning the data\n","\n","* This dataset has HTML markup\n","* Python regular expressions \n","* [Pands supports regular expressions](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.10-Working-With-Strings.ipynb) (VanderPlas) -- github.com"]},{"cell_type":"code","metadata":{"id":"RZVRxIEeXvJR"},"source":["# An example of markup inside a document\n","df.loc[0, 'review'][-50:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hD9FwYTYZ24u"},"source":["# Remove HTML, keep imoticons (but take off their noses)\n","import re\n","def preprocessor(text):\n","    text = re.sub('<[^>]*>', '', text)\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n","                        text)\n","    text = (re.sub('[\\W]+', ' ', text.lower()) +\n","        ' '.join(emoticons).replace('-', ''))\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJ9aYmuIr0fZ"},"source":["# Test it\n","preprocessor(\"</a>This :) is :( a test :-)!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_DuEaYusXYl"},"source":["# Apply it\n","df['review'] = df['review'].apply(preprocessor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FfdR1jGt52f"},"source":["# Verify it\n","df.loc[0, 'review'][-50:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hYlZ9w_LcchJ"},"source":["# Tokenizer\n","\n","* you an tokenize documents by simply splitting them into individual words at their whitespace characters\n","* you can also use \"word stemming\" to transform words to their root form\n","  * the Porter stemmer algorithm was published in 1980"]},{"cell_type":"code","metadata":{"id":"QyF6ZDZ6cFKE"},"source":["from nltk.stem.porter import PorterStemmer\n","\n","porter = PorterStemmer()\n","\n","def tokenizer(text):\n","    return text.split()\n","\n","def tokenizer_porter(text):\n","    return [porter.stem(word) for word in text.split()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DL8Dcixxu-sy"},"source":["# Compare a simple tokenizer\n","tokenizer('runners like running and thus they run')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lh1Gvb86vCiS"},"source":["# ...with a Porter stemmer algorithm -- notice what happens to \"thus\"!\n","tokenizer_porter('runners like running and thus they run')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0sHtVOYNZxDh"},"source":["# Load and remove some stop words\n","\n"]},{"cell_type":"code","metadata":{"id":"lpDuAfgkZz-H"},"source":["import nltk\n","\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbalSoKzZ_D5"},"source":["from nltk.corpus import stopwords\n","\n","stop = stopwords.words('english')\n","[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:]\n","if w not in stop]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4fzief6wrvO"},"source":["# Train/test split"]},{"cell_type":"code","metadata":{"id":"Vje-026cY58G"},"source":["X_train = df.loc[:25000, 'review'].values\n","y_train = df.loc[:25000, 'sentiment'].values\n","X_test = df.loc[25000:, 'review'].values\n","y_test = df.loc[25000:, 'sentiment'].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GYcwXyM5wx_H"},"source":["# Logistic regression\n","\n","* Parameter tuning with cross validation\n","* The next cell will take a long time (up to an hour)\n","* The cell after that searches a reduced parameter space"]},{"cell_type":"code","metadata":{"id":"SnSovmAtZikn"},"source":["# Don't run this cell, unless you want to wait a while\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","\n","tfidf = TfidfVectorizer(strip_accents=None,\n","                        lowercase=False,\n","                        preprocessor=None)\n","\n","# This param_grid results in 240 model runs, which takes 30-60 minutes\n","param_grid = [{'vect__ngram_range': [(1, 1)],\n","               'vect__stop_words': [stop, None],\n","               'vect__tokenizer': [tokenizer, tokenizer_porter],\n","               'clf__penalty': ['l1', 'l2'],\n","               'clf__C': [1.0, 10.0, 100.0]},\n","              {'vect__ngram_range': [(1, 1)],\n","               'vect__stop_words': [stop, None],\n","               'vect__tokenizer': [tokenizer, tokenizer_porter],\n","               'vect__use_idf':[False],\n","               'vect__norm':[None],\n","               'clf__penalty': ['l1', 'l2'],\n","               'clf__C': [1.0, 10.0, 100.0]},\n","              ]\n","\n","lr_tfidf = Pipeline([('vect', tfidf),\n","                     ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n","\n","gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n","                           scoring='accuracy',\n","                           cv=5,\n","                           verbose=2,\n","                           n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dv_HHSUzczg3"},"source":["# This param_grid involves 40 models, and runs in under 4 minutes in Colab\n","param_grid = [{'vect__ngram_range': [(1, 1)],\n","               'vect__stop_words': [stop, None],\n","               'vect__tokenizer': [tokenizer],\n","               'clf__penalty': ['l1', 'l2'],\n","               'clf__C': [1.0, 10.0]},\n","              ]\n","\n","gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n","                           scoring='accuracy',\n","                           cv=5,\n","                           verbose=2,\n","                           n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOYSykstxQpq"},"source":["# Compare the train/test performance\n","\n","* CV accuracy is 0.887\n","* Test accuracy is 0.893\n","* Train accuracy (without CV) is 0.997"]},{"cell_type":"code","metadata":{"id":"_hROHiDNc8l7"},"source":["gs_lr_tfidf.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1CDn6XKdUb-"},"source":["print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n","print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xXWvIysdeDM"},"source":["# Test accuracy here is 0.893, which is larger than the CV accuracy of 0.887\n","clf = gs_lr_tfidf.best_estimator_\n","print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4dqj9jGLwrP"},"source":["# But training accuracy (without CV averaging) is 0.997 -- this could be overfitting\n","print('Training Accuracy: %.3f' % clf.score(X_train, y_train))"],"execution_count":null,"outputs":[]}]}