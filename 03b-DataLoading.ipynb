{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03b-DataLoading.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN07aAmaBW6Dg0gjn+5upZn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"whmyjPaP9km9"},"source":["<table align=\"center\">\n","   <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ds5110/summer-2021/blob/master/03b-DataLoading.ipynb\">\n","<img src=\"https://github.com/ds5110/summer-2021/raw/master/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"KCjHJE42Aax2"},"source":["# 3b -- Data Loading\n","\n","### Reading/References\n","\n","* [Python for Data Analysis, 2nd Ed](https://github.com/wesm/pydata-book) (McKinney 2017) -- github\n","  * [ch05.ipynb](https://github.com/wesm/pydata-book/blob/2nd-edition/ch05.ipynb) getting started with pandas -- github\n","  * [ch06.ipynb](https://github.com/wesm/pydata-book/blob/2nd-edition/ch06.ipynb) data loading & storage -- github\n","  * [ch07.ipynb](https://github.com/wesm/pydata-book/blob/2nd-edition/ch07.ipynb) cleaning and preparation -- github\n"]},{"cell_type":"code","metadata":{"id":"FkpiiE-9ATVc"},"source":["# McKinney setup -- standard practice for a pro\n","# import numpy as np\n","# import pandas as pd\n","# PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n","# pd.options.display.max_rows = 20\n","# np.random.seed(12345)\n","# import matplotlib.pyplot as plt\n","# plt.rc('figure', figsize=(10, 6))\n","# np.set_printoptions(precision=4, suppress=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0ANJXwl1LmA"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zx5fKKG6QGt"},"source":["# Loading data with Pandas\n","\n","There are many ways it can be done...\n","\n","* `read_csv` -- load delimited data from a file, URL, or file-like object; use comma as default delimiter\n","* `read_fwf` -- data in fixed-width column format (i.e., no delimiters)\n","* `read_clipboard` -- version of read_csv that reads data from the clipboard; useful for converting tables from web pages\n","* `read_excel` -- tabular data from an Excel XLS or XLSX file\n","* `read_hdf` -- HDF5 files written by pandas\n","* `read_html` -- read all tables found in the given HTML document\n","* `read_json` -- data from a JSON (JavaScript Object Notation) string representation\n","* `read_msgpack` -- pandas data encoded using the MessagePack binary format\n","* `read_pickle` -- an arbitrary object stored in Python pickle format\n","* `read_sas` -- a SAS dataset stored in one of the SAS systemâ€™s custom storage formats\n","* `read_sql` -- the results of a SQL query (using SQLAlchemy) as a pandas DataFrame\n","* `read_stata` -- a dataset from Stata file format\n","* `read_feather` -- the Feather binary file format\n","  * https://wesmckinney.com/pages/about.html -- Feb 2020\n","  * https://wesmckinney.com/blog/feather-arrow-future/ -- Oct 2017\n","  * https://wesmckinney.com/blog/apache-arrow-pandas-internals/ -- Sep 2017"]},{"cell_type":"markdown","metadata":{"id":"Cf8VVVQc1UMN"},"source":["# Loading a CSV from github\n","\n","Navigate to the file of interest and copy the \"Raw\" URL\n","\n","* https://github.com/wesm/pydata-book/tree/2nd-edition/examples"]},{"cell_type":"code","metadata":{"id":"Y2W4giRC2WJn"},"source":["url = \"https://github.com/wesm/pydata-book/raw/2nd-edition/examples/ex1.csv\"\n","\n","df = pd.read_csv(url)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WhdrXbV4OER"},"source":["# Loading a large file\n","url = \"https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/examples/ex6.csv\"\n","\n","df = pd.read_csv(url)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTZpkRi_5Oq6"},"source":["# Reading a file in pieces\n","\n","pd.read_csv(url, nrows=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dQwOBe7UAUyX"},"source":["## Dates & times\n","\n","As may be familiar by now, there are core Python capabilities, NumPy extensions, and Pandas conveniences built on top.\n","\n","* [03.11 Working with Time Series.ipynb](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.11-Working-with-Time-Series.ipynb) -- a whirwind tour with an interesting example\n","* [pandas.Series.dt](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html) API reference docs -- pandas.pydata.org"]},{"cell_type":"code","metadata":{"id":"Kfmtw2PXWvAM"},"source":["# the built-in datetime module allows you to create a date object\n","from datetime import datetime\n","\n","dt = datetime(year=2015, month=7, day=4)\n","\n","print(type(dt))\n","print(dt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTcjFQXOXNEg"},"source":["# the third-party dateutil module parses text into datetime.datetime objects\n","from dateutil import parser\n","date = parser.parse(\"4th of July, 2015\")\n","print(type(date))\n","print(date)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_oXcoVaYCJA"},"source":["# once you have a datetime object, you can do things like print the day of the week\n","date.strftime('%A')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-J6J-gDeJY1"},"source":["# pandas Series.dt object\n","seconds_series = pd.Series(pd.date_range(\"2000-01-01\", periods=3, freq=\"s\"))\n","\n","print(type(seconds_series))\n","print(seconds_series.dt.second)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XnzTeVkzB43L"},"source":["# HTML\n","\n","Read HTML tables into a list of DataFrame objects.\n","\n","Also known as \"web scraping\"\n","\n","A demo with dates..."]},{"cell_type":"code","metadata":{"id":"OqtlX8XxB3OO"},"source":["# Read tables in an HTML file\n","\n","url = \"https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/examples/fdic_failed_bank_list.html\"\n","\n","tables = pd.read_html(url)\n","\n","print(type(tables))\n","print(len(tables))\n","print(type(tables[0]))\n","\n","failures = tables[0]\n","failures.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7vSpRqECpd1"},"source":["# It's worth inspecting thing in detail, at least once.\n","print('1', type(failures['Closing Date'])) # a Series object pulled from the DF\n","print('2', type(failures['Closing Date'][0])) # a string\n","print('3', failures.loc[0, 'Closing Date']) # formatted as a date\n","\n","close_timestamps = pd.to_datetime(failures['Closing Date'])\n","\n","print('4', type(close_timestamps)) # a Series object\n","print('5', type(close_timestamps[0])) # a pandas Timestamp object\n","print('6', close_timestamps[0]) # a pandas Timestamp object (printed)\n","\n","print('value counts:', close_timestamps.dt.year.value_counts())\n","\n","close_timestamps.dt.year\n","\n","close_timestamps[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YNarJMIyNgj6"},"source":["# JSON\n","\n","A web standard for data (as distinct from web scraping)\n"]},{"cell_type":"code","metadata":{"id":"Aj4JndqKNpOp"},"source":["import json\n","\n","obj = \"\"\"\n","{\"name\": \"Wes\",\n"," \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n"," \"pet\": null,\n"," \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n","              {\"name\": \"Katie\", \"age\": 38,\n","               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n","}\n","\"\"\"\n","\n","print(type(obj))\n","\n","result = json.loads(obj)\n","print(type(result))\n","\n","result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Kbu6HoHVxjF"},"source":["# Web API\n","\n","* [Python requests](https://docs.python-requests.org/en/master/) can be used for 2-way communication to APIs\n","  * [Requests quickstart](https://docs.python-requests.org/en/latest/user/quickstart/) -- python-requests.org\n","* The typical response of modern Web APIs is JSON\n","* For example, github has a nice Web API for publicly accessible repositories\n","* Use the online documentation to get more information about various objects and methods..."]},{"cell_type":"code","metadata":{"id":"Kp5GBEk7V5nV"},"source":["# Import some data from the Github web API\n","import requests\n","\n","url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n","\n","resp = requests.get(url)\n","print('1:', type(resp))\n","print('2:', resp)\n","\n","# Parse the response as JSON\n","data = resp.json()\n","\n","# inspect the data object\n","print('3:', type(data)) # list\n","print('4:', type(data[0])) # first element in the list\n","print('5:', data[0]['title']) # one attribute in that element\n","print('6:', data[0]) # that element in its entirety\n","\n","# Create a DataFrame from the list\n","issues = pd.DataFrame(data, columns=['number', 'title',\n","                                    'labels', 'state'])\n","print('7: the dataframe:')\n","issues"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-chUvtEUlYz"},"source":["## USGS Earthquake data feed\n","\n","* [Earthqake data from the USGS Hazards Program](https://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php) -- usgs.gov\n","\n","EXERCISE: How many earthquakes in the last day?"]},{"cell_type":"markdown","metadata":{"id":"tOlvfOZSNzq0"},"source":["# Missing data\n","\n","There are several ways to represent missing data.\n","\n","* None -- native Python singleton object often used for missing data (slow)\n","* [np.nan](https://numpy.org/doc/stable/reference/constants.html?highlight=nan#numpy.nan) -- IEEE floating point representation of \"Not A Number\" (fast)\n","* pd.NA -- pandas._libs.missing.NAType (special object)"]},{"cell_type":"code","metadata":{"id":"3fkuzFZqmLtf"},"source":["# None is a \"NoneType\", np.nan is a float, pd.NA is a special object\n","print(type(3))\n","print(type(3.14159))\n","print(type(np.nan))\n","print(type(None))\n","\n","arr = np.array([1, 42])\n","print('arr.dtype (before):', arr.dtype)\n","#arr = arr + None  # this throws a TypeError\n","arr = np.array([1, 42]) + pd.NA\n","print('arr.dtype (during):', arr.dtype)\n","arr = arr + np.nan # this works, but converts the dtype\n","print('arr.dtype (after):', arr.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c08N385IbTJN"},"source":["# Be careful when checking a numpy array for missing data\n","# Try each of these in succession\n","#arr = np.array(['aardvark', np.nan]) # This will throw an Error because 'aardvark' is a string\n","#arr = np.array([1, 2, None]) # This will also throw an error because None is an object\n","arr = np.array([1,2, np.nan]) # This works because the array contains \"numeric\" values\n","np.isnan(arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4ezLTkJ65N7"},"source":["np.array(['hello', 'world', np.nan]) # dtype: unicode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6xVwuCt6_hR"},"source":["np.array(['hello', 'world', None]) # dtype: object"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z59J46Mk2Ks8"},"source":["# Missing data in Pandas\n","\n","* Pandas has its own pd.NA (relatively new)\n","* In Pandas, NaN and None are nearly interchangeable, with surprising behavior\n","* [Working with missing data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html) -- pandas.pydata.org"]},{"cell_type":"code","metadata":{"id":"O1Nv1my5NcCe"},"source":["# Pandas is more forgiving, but some results might be surprising\n","arr = np.array(['aardvark', pd.NA, np.nan, None])\n","print(pd.isnull(arr))\n","\n","arr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76QBv5GCBcoc"},"source":["# Notice that this Series is dtype: Int64\n","arr = pd.Series([2, pd.NA], dtype=\"Int64\")\n","arr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmPtaQu9Eb8w"},"source":["# And NA has its own type\n","type(pd.NA)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5X_6NTN7au-"},"source":["# Pandas converts None to np.nan in this Series with dtype: float64\n","pd.Series([None, 42])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRPl8KW22oju"},"source":["# Pandas converts the Series to dtype: object if it has a pd.NA\n","pd.Series([42, pd.NA])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LJP2Hcaj2iB"},"source":["# But you can specify dtype=\"Int64\"\n","pd.Series([42, pd.NA], dtype=\"Int64\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"axnoKa48q1qX"},"source":["# Handling missing values\n","\n","Methods for dealing with missing data in Pandas\n","\n","* `isnull()`: Generate a boolean mask indicating missing values\n","* `notnull()`: Opposite of isnull()\n","* `dropna()`: Return a filtered version of the data\n","* `fillna()`: Return a copy of the data with missing values filled or imputed"]},{"cell_type":"code","metadata":{"id":"UNMOtBEbrb_I"},"source":["# These methods work with Pandas Series\n","series = pd.DataFrame([1, np.nan, 'hello', None])\n","\n","# The return value is a copy (see reference docs)\n","# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dropna.html\n","series.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J14mJDtdtN4m"},"source":["# They also work with a Pandas DataFrame\n","df = pd.DataFrame([[1,      np.nan, 2],\n","                   [2,      3,      5],\n","                   [pd.NA, None, np.nan],\n","                   [np.nan, 4,      6]])\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vv62y25WtZSm"},"source":["# By default -- the entire row is dropped if it contains an NA\n","df.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmZYVOY8to29"},"source":["# You can override the default behavior, and drop columns instead\n","df.dropna(axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9M1yR0gt48L"},"source":["# You can also specify that all elements must be NA before dropping a row/column\n","df.dropna(how='all')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGSrNszSuw_Z"},"source":["# You can fill null values in any of several ways. With a single value...\n","df.fillna('42')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fexzQG7Ju_X7"},"source":["# The previous value (default: along index=0)\n","df.fillna(method='bfill')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DtMwpUSwH2Y"},"source":["# The previous value along axis=1\n","df.fillna(method='bfill', axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxpzDQqBplcw"},"source":["# Missing penguins"]},{"cell_type":"code","metadata":{"id":"DFZq0kthphf4"},"source":["import seaborn as sns\n","\n","# load the \"penguins\" dataset from seaborn\n","penguins = sns.load_dataset(\"penguins\")\n","\n","# inspect the dataset (note: there are some NaNs)\n","penguins"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4007nv9pkS5"},"source":["penguins.isnull()\n","penguins.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IOLStc41HA0W"},"source":["## Q: Where are the missing penguins?"]},{"cell_type":"code","metadata":{"id":"6oi3md8jsONR"},"source":["df = penguins[penguins['sex'].isnull()]\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEEozue7HMw4"},"source":["sns.pairplot(df, hue=\"species\");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZCwKD4-kmbl"},"source":["### Q: Why does the plot above have 5 columns & rows, whereas the next one has only 4?"]},{"cell_type":"code","metadata":{"id":"SZWCJ4KkHvu9"},"source":["sns.pairplot(penguins, hue=\"species\");"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LbwySkDID2E"},"source":["# Inspect all the penguins\n","penguins"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2xsm4lCkEEv"},"source":["# Inspect the missing penguins\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eb4AUC7kHWN"},"source":["# A: Specify variables within data to use, otherwise use every column with a numeric datatype\n","# Get this from API ref docs: https://seaborn.pydata.org/generated/seaborn.pairplot.html\n","# 5th variable because missing penguins are all floats (nan), not float/string combination\n","# Fix things by specifying \"vars\"\n","vars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n","sns.pairplot(df, hue=\"species\", vars=vars)\n","# all penguins\n","print(type(penguins.loc[3, 'sex']))\n","print(penguins.loc[3, 'sex'])\n","print(penguins['sex'].dtype)\n","\n","# missing penguins\n","print(type(df.loc[3, 'sex']))\n","print(df.loc[3, 'sex'])\n","print(df['sex'].dtype)"],"execution_count":null,"outputs":[]}]}